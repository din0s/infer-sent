{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# The path of the data directory (where the ALIGNED glove embeddings are)\n",
    "DATA_DIR = \"./data\"\n",
    "\n",
    "# The path of the tensorboard logs directory\n",
    "LOGS_DIR = \"./lisa_logs\"\n",
    "\n",
    "# The order in which the models should appear in the tables\n",
    "MODEL_ORDER = ['baseline', 'lstm', 'bilstm', 'bilstm-max']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Package Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from encoders import *\n",
    "from glove import GloVeEmbeddings\n",
    "from models import Classifier\n",
    "from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "\n",
    "import glob, os, re, spacy, torch\n",
    "import pandas as pd\n",
    "\n",
    "if not spacy.util.is_package(\"en_core_web_sm\"):\n",
    "    print(\"Downloading SpaCy English model (small)\")\n",
    "    spacy.cli.download(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Model Demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading pre-trained GloVe embeddings from disk\n"
     ]
    }
   ],
   "source": [
    "glove = GloVeEmbeddings(DATA_DIR)\n",
    "tokenizer = get_tokenizer('spacy', language='en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "CKPTS_GLOB = \"*/*/checkpoints/*.ckpt\"\n",
    "CKPTS_PATTERN = r\"([^\\/]+)\\/version_\\d+.*\\.ckpt\"\n",
    "\n",
    "EMBED_DIM = 300\n",
    "LSTM_STATE_DIM = 2048\n",
    "\n",
    "models = {}\n",
    "for ckpt_name in glob.glob(os.path.join(LOGS_DIR, CKPTS_GLOB)):\n",
    "    # Extract model name from checkpoint name\n",
    "    res = re.search(CKPTS_PATTERN, ckpt_name)\n",
    "    model_name = res.group(1)\n",
    "\n",
    "    if model_name == \"baseline\":\n",
    "        repr_dim = EMBED_DIM\n",
    "        encoder = BaselineEncoder()\n",
    "    else:\n",
    "        repr_dim = LSTM_STATE_DIM\n",
    "\n",
    "        if model_name == \"lstm\":\n",
    "            encoder = LSTMEncoder(EMBED_DIM, LSTM_STATE_DIM)\n",
    "        elif model_name == \"bilstm\":\n",
    "            repr_dim *= 2\n",
    "            encoder = BiLSTMEncoder(EMBED_DIM, LSTM_STATE_DIM)\n",
    "        elif model_name == \"bilstm-max\":\n",
    "            repr_dim *= 2\n",
    "            encoder = MaxBiLSTMEncoder(EMBED_DIM, LSTM_STATE_DIM)\n",
    "        else:\n",
    "            print(f\"Encountered unsupported encoder architecture '{model_name}'\")\n",
    "            continue\n",
    "\n",
    "    model_args = {\"embeddings\": glove.vectors, \"encoder\": encoder}\n",
    "    model = Classifier.load_from_checkpoint(ckpt_name, **model_args)\n",
    "    model.load_embeddings(glove.vectors)\n",
    "    models[model_name] = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "INT_TO_CLASS = {\n",
    "    0: \"entailment\",\n",
    "    1: \"neutral\",\n",
    "    2: \"contradiction\"\n",
    "}\n",
    "\n",
    "@torch.no_grad()\n",
    "def inference(model_name: str, premise: str, hypothesis: str) -> str:\n",
    "    if model_name not in models:\n",
    "        raise Exception(f\"Unknown encoder type '{model_name}'!\")\n",
    "\n",
    "    # Load model from dict\n",
    "    model = models[model_name]\n",
    "\n",
    "    # Lowercase + tokenize\n",
    "    premise = tokenizer(premise.lower())\n",
    "    hypothesis = tokenizer(hypothesis.lower())\n",
    "\n",
    "    # Convert list of tokens to list of IDs\n",
    "    premise = [glove.get_id(t) for t in premise]\n",
    "    hypothesis = [glove.get_id(t) for t in hypothesis]\n",
    "\n",
    "    # Convert to tensors with an extra dimension (batch_size=1)\n",
    "    p = torch.IntTensor(premise).unsqueeze(0)\n",
    "    h = torch.IntTensor(hypothesis).unsqueeze(0)\n",
    "\n",
    "    # Count length of each sentence\n",
    "    p_len = torch.LongTensor([len(premise)])\n",
    "    h_len = torch.LongTensor([len(hypothesis)])\n",
    "\n",
    "    logits = model(p, h, p_len, h_len)\n",
    "    category = INT_TO_CLASS[logits.argmax().item()]\n",
    "    return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'contradiction'"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# must be one of: 'baseline', 'lstm', 'bilstm', 'bilstm-max'\n",
    "MODEL_NAME = 'bilstm-max'\n",
    "\n",
    "PREMISE = 'The dog is eating.'\n",
    "HYPOTHESIS = 'The dog sleeps.'\n",
    "\n",
    "inference(MODEL_NAME, PREMISE, HYPOTHESIS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Results Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    is_max = s == s.max()\n",
    "    return ['font-weight: bold' if cell else '' for cell in is_max]\n",
    "\n",
    "def format_df(df):\n",
    "    dfs = df.style\n",
    "    dfs = dfs.apply(highlight_max)\n",
    "    dfs = dfs.format(\"{:2.2f}\")\n",
    "    dfs = dfs.set_table_styles([\n",
    "        dict(selector='thead th', props=[('text-align', 'center'), ('vertical-align', 'bottom')]),\n",
    "        dict(selector='td', props=[('text-align', 'center'), ('padding', '0.5em 1.5em')]),\n",
    "    ])\n",
    "    return dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Performance Comparison\n",
    "(corresponds to Table 3 in Conneau et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LOGS_GLOB = \"*/*\"\n",
    "LOGS_PATTERN = r\"([^\\/]+)\\/((?:version_\\d+)|(?:eval))\"\n",
    "\n",
    "nli_df = pd.DataFrame(columns=['dev', 'test'])\n",
    "for log_name in glob.glob(os.path.join(LOGS_DIR, LOGS_GLOB)):\n",
    "    # Extract model & version name from logfile name\n",
    "    res = re.search(LOGS_PATTERN, log_name)\n",
    "    model_name = res.group(1)\n",
    "    is_test = res.group(2) == \"eval\"\n",
    "\n",
    "    # Read the TFEvents file\n",
    "    ea = EventAccumulator(log_name)\n",
    "    ea.Reload()\n",
    "\n",
    "    if is_test:\n",
    "        # Read the test_acc value\n",
    "        acc = ea.Scalars('test_acc')[0].value\n",
    "    else:\n",
    "        # Read all val_acc values and pick the maximum\n",
    "        acc = max(map(lambda e: e.value, ea.Scalars('val_acc')))\n",
    "\n",
    "    # Convert accuracy to percentage\n",
    "    acc *= 100\n",
    "\n",
    "    col_name = 'test' if is_test else 'dev'\n",
    "    if model_name not in nli_df.index:\n",
    "        acc_df = pd.DataFrame.from_dict({col_name: [acc]})\n",
    "        acc_df.index = [model_name]\n",
    "\n",
    "        nli_df = pd.concat((nli_df, acc_df))\n",
    "    else:\n",
    "        nli_df.at[model_name, col_name] = acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_accuracy(df: pd.DataFrame, name: str) -> pd.DataFrame:\n",
    "    # Filter out columns that don't have a validation accuracy\n",
    "    # This is the case in non-classification tasks, such as SICK-R and STS14\n",
    "    df = df.loc[:, df.loc['devacc'].notnull()]\n",
    "\n",
    "    # Extract the validation accuracy for each task\n",
    "    val_acc = df.loc['devacc']\n",
    "\n",
    "    # Calculate the weighing factor for micro-accuracy\n",
    "    n_val = df.loc['ndev']\n",
    "    weight = n_val / n_val.sum()\n",
    "\n",
    "    # Calculate the macro and micro accuracy\n",
    "    macro = val_acc.mean()\n",
    "    micro = (val_acc * weight).sum()\n",
    "\n",
    "    # Return metrics as dataframe\n",
    "    acc_dict = {'micro': [micro], 'macro': [macro]}\n",
    "    acc_df = pd.DataFrame.from_dict(acc_dict)\n",
    "    acc_df.index = [name]\n",
    "    return acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RESULTS_GLOB = \"results_*.json\"\n",
    "RESULTS_PATTERN = r\"results*_([^\\.]+)\\.json\"\n",
    "\n",
    "transfer_df = pd.DataFrame()\n",
    "for results_file in glob.glob(os.path.join(LOGS_DIR, RESULTS_GLOB)):\n",
    "    # Extract model name from file name\n",
    "    res = re.search(RESULTS_PATTERN, results_file)\n",
    "    model_name = res.group(1)\n",
    "\n",
    "    # Convert json to dataframe\n",
    "    df = pd.read_json(results_file)\n",
    "    # Calculate accuracies and create dataframe row\n",
    "    model_accs = calculate_accuracy(df, model_name)\n",
    "\n",
    "    # Append row to transfer results dataframe\n",
    "    transfer_df = pd.concat((transfer_df, model_accs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f3d78d17dc0>",
      "text/html": "<style  type=\"text/css\" >\n    #T_96d58_ thead th {\n          text-align: center;\n          vertical-align: bottom;\n    }    #T_96d58_ td {\n          text-align: center;\n          padding: 0.5em 1.5em;\n    }#T_96d58_row3_col0,#T_96d58_row3_col1,#T_96d58_row3_col2,#T_96d58_row3_col3{\n            font-weight:  bold;\n        }</style><table id=\"T_96d58_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" colspan=\"2\">NLI</th>        <th class=\"col_heading level0 col2\" colspan=\"2\">Transfer</th>    </tr>    <tr>        <th class=\"blank level1\" ></th>        <th class=\"col_heading level1 col0\" >dev</th>        <th class=\"col_heading level1 col1\" >test</th>        <th class=\"col_heading level1 col2\" >micro</th>        <th class=\"col_heading level1 col3\" >macro</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_96d58_level0_row0\" class=\"row_heading level0 row0\" >baseline</th>\n                        <td id=\"T_96d58_row0_col0\" class=\"data row0 col0\" >65.72</td>\n                        <td id=\"T_96d58_row0_col1\" class=\"data row0 col1\" >65.33</td>\n                        <td id=\"T_96d58_row0_col2\" class=\"data row0 col2\" >79.83</td>\n                        <td id=\"T_96d58_row0_col3\" class=\"data row0 col3\" >78.39</td>\n            </tr>\n            <tr>\n                        <th id=\"T_96d58_level0_row1\" class=\"row_heading level0 row1\" >lstm</th>\n                        <td id=\"T_96d58_row1_col0\" class=\"data row1 col0\" >81.45</td>\n                        <td id=\"T_96d58_row1_col1\" class=\"data row1 col1\" >81.26</td>\n                        <td id=\"T_96d58_row1_col2\" class=\"data row1 col2\" >77.32</td>\n                        <td id=\"T_96d58_row1_col3\" class=\"data row1 col3\" >76.42</td>\n            </tr>\n            <tr>\n                        <th id=\"T_96d58_level0_row2\" class=\"row_heading level0 row2\" >bilstm</th>\n                        <td id=\"T_96d58_row2_col0\" class=\"data row2 col0\" >80.87</td>\n                        <td id=\"T_96d58_row2_col1\" class=\"data row2 col1\" >80.66</td>\n                        <td id=\"T_96d58_row2_col2\" class=\"data row2 col2\" >79.95</td>\n                        <td id=\"T_96d58_row2_col3\" class=\"data row2 col3\" >79.28</td>\n            </tr>\n            <tr>\n                        <th id=\"T_96d58_level0_row3\" class=\"row_heading level0 row3\" >bilstm-max</th>\n                        <td id=\"T_96d58_row3_col0\" class=\"data row3 col0\" >84.37</td>\n                        <td id=\"T_96d58_row3_col1\" class=\"data row3 col1\" >83.85</td>\n                        <td id=\"T_96d58_row3_col2\" class=\"data row3 col2\" >81.85</td>\n                        <td id=\"T_96d58_row3_col3\" class=\"data row3 col3\" >81.16</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df = pd.concat((nli_df, transfer_df), axis=1, keys=['NLI', 'Transfer'])\n",
    "performance_df.reindex(MODEL_ORDER)\n",
    "\n",
    "format_df(performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### SentEval Comparison\n",
    "(corresponds to Table 4 in Conneau et al.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<pandas.io.formats.style.Styler at 0x7f3d7130ff40>",
      "text/html": "<style  type=\"text/css\" >\n    #T_301eb_ thead th {\n          text-align: center;\n          vertical-align: bottom;\n    }    #T_301eb_ td {\n          text-align: center;\n          padding: 0.5em 1.5em;\n    }#T_301eb_row1_col7,#T_301eb_row3_col0,#T_301eb_row3_col1,#T_301eb_row3_col2,#T_301eb_row3_col3,#T_301eb_row3_col4,#T_301eb_row3_col5,#T_301eb_row3_col6,#T_301eb_row3_col8,#T_301eb_row3_col9,#T_301eb_row3_col10,#T_301eb_row3_col11{\n            font-weight:  bold;\n        }</style><table id=\"T_301eb_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >MR</th>        <th class=\"col_heading level0 col1\" >CR</th>        <th class=\"col_heading level0 col2\" >SUBJ</th>        <th class=\"col_heading level0 col3\" >MPQA</th>        <th class=\"col_heading level0 col4\" >SST</th>        <th class=\"col_heading level0 col5\" >TREC</th>        <th class=\"col_heading level0 col6\" >MRPC<br>accuracy</th>        <th class=\"col_heading level0 col7\" >MRPC<br>F1-score</th>        <th class=\"col_heading level0 col8\" >SICK-R</th>        <th class=\"col_heading level0 col9\" >SICK-E</th>        <th class=\"col_heading level0 col10\" >STS14<br>average<br>pearson</th>        <th class=\"col_heading level0 col11\" >STS14<br>weighted<br>pearson</th>    </tr></thead><tbody>\n                <tr>\n                        <th id=\"T_301eb_level0_row0\" class=\"row_heading level0 row0\" >baseline</th>\n                        <td id=\"T_301eb_row0_col0\" class=\"data row0 col0\" >75.07</td>\n                        <td id=\"T_301eb_row0_col1\" class=\"data row0 col1\" >79.23</td>\n                        <td id=\"T_301eb_row0_col2\" class=\"data row0 col2\" >90.67</td>\n                        <td id=\"T_301eb_row0_col3\" class=\"data row0 col3\" >84.76</td>\n                        <td id=\"T_301eb_row0_col4\" class=\"data row0 col4\" >78.25</td>\n                        <td id=\"T_301eb_row0_col5\" class=\"data row0 col5\" >71.40</td>\n                        <td id=\"T_301eb_row0_col6\" class=\"data row0 col6\" >70.90</td>\n                        <td id=\"T_301eb_row0_col7\" class=\"data row0 col7\" >80.19</td>\n                        <td id=\"T_301eb_row0_col8\" class=\"data row0 col8\" >0.80</td>\n                        <td id=\"T_301eb_row0_col9\" class=\"data row0 col9\" >78.22</td>\n                        <td id=\"T_301eb_row0_col10\" class=\"data row0 col10\" >0.45</td>\n                        <td id=\"T_301eb_row0_col11\" class=\"data row0 col11\" >0.46</td>\n            </tr>\n            <tr>\n                        <th id=\"T_301eb_level0_row1\" class=\"row_heading level0 row1\" >lstm</th>\n                        <td id=\"T_301eb_row1_col0\" class=\"data row1 col0\" >72.62</td>\n                        <td id=\"T_301eb_row1_col1\" class=\"data row1 col1\" >76.71</td>\n                        <td id=\"T_301eb_row1_col2\" class=\"data row1 col2\" >86.53</td>\n                        <td id=\"T_301eb_row1_col3\" class=\"data row1 col3\" >85.03</td>\n                        <td id=\"T_301eb_row1_col4\" class=\"data row1 col4\" >76.77</td>\n                        <td id=\"T_301eb_row1_col5\" class=\"data row1 col5\" >72.20</td>\n                        <td id=\"T_301eb_row1_col6\" class=\"data row1 col6\" >71.65</td>\n                        <td id=\"T_301eb_row1_col7\" class=\"data row1 col7\" >81.36</td>\n                        <td id=\"T_301eb_row1_col8\" class=\"data row1 col8\" >0.85</td>\n                        <td id=\"T_301eb_row1_col9\" class=\"data row1 col9\" >83.42</td>\n                        <td id=\"T_301eb_row1_col10\" class=\"data row1 col10\" >0.55</td>\n                        <td id=\"T_301eb_row1_col11\" class=\"data row1 col11\" >0.56</td>\n            </tr>\n            <tr>\n                        <th id=\"T_301eb_level0_row2\" class=\"row_heading level0 row2\" >bilstm</th>\n                        <td id=\"T_301eb_row2_col0\" class=\"data row2 col0\" >73.24</td>\n                        <td id=\"T_301eb_row2_col1\" class=\"data row2 col1\" >78.49</td>\n                        <td id=\"T_301eb_row2_col2\" class=\"data row2 col2\" >89.89</td>\n                        <td id=\"T_301eb_row2_col3\" class=\"data row2 col3\" >84.98</td>\n                        <td id=\"T_301eb_row2_col4\" class=\"data row2 col4\" >78.36</td>\n                        <td id=\"T_301eb_row2_col5\" class=\"data row2 col5\" >76.80</td>\n                        <td id=\"T_301eb_row2_col6\" class=\"data row2 col6\" >72.12</td>\n                        <td id=\"T_301eb_row2_col7\" class=\"data row2 col7\" >81.06</td>\n                        <td id=\"T_301eb_row2_col8\" class=\"data row2 col8\" >0.86</td>\n                        <td id=\"T_301eb_row2_col9\" class=\"data row2 col9\" >83.46</td>\n                        <td id=\"T_301eb_row2_col10\" class=\"data row2 col10\" >0.56</td>\n                        <td id=\"T_301eb_row2_col11\" class=\"data row2 col11\" >0.58</td>\n            </tr>\n            <tr>\n                        <th id=\"T_301eb_level0_row3\" class=\"row_heading level0 row3\" >bilstm-max</th>\n                        <td id=\"T_301eb_row3_col0\" class=\"data row3 col0\" >75.80</td>\n                        <td id=\"T_301eb_row3_col1\" class=\"data row3 col1\" >81.46</td>\n                        <td id=\"T_301eb_row3_col2\" class=\"data row3 col2\" >91.20</td>\n                        <td id=\"T_301eb_row3_col3\" class=\"data row3 col3\" >85.60</td>\n                        <td id=\"T_301eb_row3_col4\" class=\"data row3 col4\" >79.13</td>\n                        <td id=\"T_301eb_row3_col5\" class=\"data row3 col5\" >79.20</td>\n                        <td id=\"T_301eb_row3_col6\" class=\"data row3 col6\" >73.10</td>\n                        <td id=\"T_301eb_row3_col7\" class=\"data row3 col7\" >81.15</td>\n                        <td id=\"T_301eb_row3_col8\" class=\"data row3 col8\" >0.88</td>\n                        <td id=\"T_301eb_row3_col9\" class=\"data row3 col9\" >85.20</td>\n                        <td id=\"T_301eb_row3_col10\" class=\"data row3 col10\" >0.65</td>\n                        <td id=\"T_301eb_row3_col11\" class=\"data row3 col11\" >0.66</td>\n            </tr>\n    </tbody></table>"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RESULTS_GLOB = \"results_*.json\"\n",
    "RESULTS_PATTERN = r\"results*_([^\\.]+)\\.json\"\n",
    "\n",
    "senteval_df = pd.DataFrame()\n",
    "for results_file in glob.glob(os.path.join(LOGS_DIR, RESULTS_GLOB)):\n",
    "    # Extract model name from file name\n",
    "    res = re.search(RESULTS_PATTERN, results_file)\n",
    "    model_name = res.group(1)\n",
    "\n",
    "    # Convert json to dataframe\n",
    "    df = pd.read_json(results_file)\n",
    "\n",
    "    # Select accuracy for classification tasks (except MRPC)\n",
    "    df_class = df.loc[['acc'], df.loc['acc'].notnull()].drop('MRPC', axis=1)\n",
    "    df_class.index = [model_name]\n",
    "\n",
    "    # Select accuracy and F1 score for the MRPC task\n",
    "    mrpc_cols = pd.MultiIndex.from_product((['MRPC'], ['acc','f1']))\n",
    "    mrpc_vals = df.loc[['acc', 'f1'], 'MRPC'].array\n",
    "    df_mrpc = pd.DataFrame([mrpc_vals], columns=mrpc_cols, index=[model_name])\n",
    "\n",
    "    # Select pearson value for the SICK-R task\n",
    "    df_sickr = pd.DataFrame(df.loc[['pearson'], 'SICKRelatedness'])\n",
    "    df_sickr.index = [model_name]\n",
    "\n",
    "    # Select pearson value(s) for the STS14 task\n",
    "    dict_sts14 = df.loc['all', 'STS14']['pearson']\n",
    "    sts14_cols = pd.MultiIndex.from_product((['STS14'], dict_sts14.keys()))\n",
    "    df_sts14 = pd.DataFrame([dict_sts14.values()], columns=sts14_cols, index=[model_name])\n",
    "\n",
    "    # Concat all tasks to one dataframe row\n",
    "    scores_df = pd.concat((df_class, df_mrpc, df_sickr, df_sts14), axis=1)\n",
    "\n",
    "    # Append row to to SentEval scores dataframe\n",
    "    senteval_df = pd.concat((senteval_df, scores_df), axis=0)\n",
    "\n",
    "TASK_ORDER = [\n",
    "    'MR', 'CR', 'SUBJ', 'MPQA', 'SST2', 'TREC',\n",
    "    ('MRPC', 'acc'), ('MRPC', 'f1'),\n",
    "    'SICKRelatedness', 'SICKEntailment',\n",
    "    ('STS14', 'mean'), ('STS14', 'wmean')\n",
    "]\n",
    "\n",
    "TASK_NAMES = TASK_ORDER.copy()\n",
    "TASK_NAMES[4] = 'SST'\n",
    "TASK_NAMES[6] = 'MRPC<br>accuracy' ; TASK_NAMES[7] = 'MRPC<br>F1-score'\n",
    "TASK_NAMES[-4] = 'SICK-R' ; TASK_NAMES[-3] = 'SICK-E'\n",
    "TASK_NAMES[-2] = 'STS14<br>average<br>pearson' ; TASK_NAMES[-1] = 'STS14<br>weighted<br>pearson'\n",
    "\n",
    "senteval_df = senteval_df.reindex(MODEL_ORDER).T.reindex(TASK_ORDER).T\n",
    "senteval_df.columns = TASK_NAMES  # rename to match the paper's order\n",
    "\n",
    "format_df(senteval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Error Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}